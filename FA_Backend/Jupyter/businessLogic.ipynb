{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Misc.env_vars as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.models import dq_col_sum, dq_agg_sum, dq_agg_view\n",
    "from Logic.base_queries import run_stmt\n",
    "import Misc.env_vars as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Logic import base_queries as bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Select, func, or_, desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Cards "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Orders with Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_rng = bq.get_date_range()\n",
    "\n",
    "max_date = dt_rng[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_dt = max_date - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cards = (\n",
    "    Select(\n",
    "        dq_agg_sum.c.ord_date.label(\"Order_Date\"),\n",
    "        func.sum(dq_agg_sum.c.total_orders).label(\"Total_Orders\"),\n",
    "        func.sum(dq_agg_sum.c.total_canceled_orders).label(\"Cancelled_Orders\")\n",
    "    ).where(or_(dq_agg_sum.c.ord_date == max_date, dq_agg_sum.c.ord_date == prev_dt))\n",
    "    .group_by(dq_agg_sum.c.ord_date)\n",
    "    .order_by(desc(dq_agg_sum.c.ord_date))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_stmt(top_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.loc[:,[\"Order_Date\"]] = df_temp[\"Order_Date\"].astype()\n",
    "df_temp.loc[:,\"Total_Orders\"] = df_temp[\"Total_Orders\"].astype(int)\n",
    "df_temp.loc[:,\"Cancelled_Orders\"] = df_temp[\"Cancelled_Orders\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[\"Cancel_percentage\"] = df_temp[\"Cancelled_Orders\"] / df_temp[\"Total_Orders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[\"Completed_percentage\"] = (df_temp[\"Total_Orders\"] - df_temp[\"Cancelled_Orders\"])/ df_temp[\"Total_Orders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrices(df: pd.DataFrame, col_name: str):\n",
    "    old_val = np.round(df[col_name][1],4)\n",
    "    new_val = np.round(df[col_name][0],4)\n",
    "    diff = new_val - old_val\n",
    "    per_diff = np.round((diff/old_val)*100,4)\n",
    "    return new_val, diff, per_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt, td, tp = calc_metrices(df_temp, \"Total_Orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_orders = {\n",
    "    \"title\":\"Total Orders\",\n",
    "    \"count\": str(tt),\n",
    "    \"increased\" : False if td < 0 else True,\n",
    "    \"variancePercentage\" : str(tp),\n",
    "    \"varianceText\": \"vs Yesterday\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc, cd, cp = calc_metrices(df_temp, \"Cancelled_Orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cancellation = {\n",
    "    \"title\":\"Cancelled Orders\",\n",
    "    \"count\": str(tc),\n",
    "    \"increased\" : False if cd < 0 else True,\n",
    "    \"variancePercentage\" : str(cp),\n",
    "    \"varianceText\": \"vs Yesterday\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cct, ccd, ccp = calc_metrices(df_temp, \"Cancel_percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancel_percentage = {\n",
    "    \"title\":\"Order Cancellation %\",\n",
    "    \"count\": str(cct),\n",
    "    \"increased\" : False if ccd < 0 else True,\n",
    "    \"variancePercentage\" : str(ccp),\n",
    "    \"varianceText\": \"vs Yesterday\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot, cod, cop = calc_metrices(df_temp, \"Completed_percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compl_percentage = {\n",
    "    \"title\":\"Order Completion %\",\n",
    "    \"count\": str(cot),\n",
    "    \"increased\" : False if cod < 0 else True,\n",
    "    \"variancePercentage\" : str(cop),\n",
    "    \"varianceText\": \"vs Yesterday\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = [total_orders, total_cancellation, cancel_percentage,compl_percentage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Columns Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sum_comp = (\n",
    "    Select(\n",
    "        dq_agg_view.c.ord_date, \n",
    "        func.sum(dq_agg_view.c.total_orders).label(\"total_orders\"),\n",
    "        func.sum(dq_agg_view.c.null_fulfilment_id).label(\"null_fulfilment_id\"),\n",
    "        func.sum(dq_agg_view.c.null_net_tran_id).label(\"null_net_tran_id\"),\n",
    "        func.sum(dq_agg_view.c.null_qty.label(\"null_qty\")),\n",
    "        func.sum(dq_agg_view.c.null_itm_fulfilment_id).label(\"null_itm_fulfilment_id\"),\n",
    "        func.sum(dq_agg_view.c.null_del_pc).label(\"null_del_pc\"),\n",
    "        func.sum(dq_agg_view.c.null_created_date_time).label(\"null_created_date_time\"),\n",
    "        func.sum(dq_agg_view.c.null_domain).label(\"null_domain\"),\n",
    "        func.sum(dq_agg_view.c.null_del_cty).label(\"null_del_cty\"),\n",
    "        func.sum(dq_agg_view.c.null_ord_stats).label(\"null_ord_stats\"),\n",
    "        func.sum(dq_agg_view.c.null_fulfil_status).label(\"null_fulfil_status\"),\n",
    "        func.sum(dq_agg_view.c.null_itm_cat).label(\"null_itm_cat\"),\n",
    "        func.sum(dq_agg_view.c.null_cat_cons).label(\"null_cat_cons\"),\n",
    "        func.sum(dq_agg_view.c.null_sell_pincode).label(\"null_sell_pincode\"),\n",
    "        func.sum(dq_agg_view.c.null_prov_id).label(\"null_prov_id\"),\n",
    "        func.sum(dq_agg_view.c.null_itm_id).label(\"null_itm_id\"),\n",
    "        func.sum(dq_agg_view.c.null_sell_np).label(\"null_sell_np\"),\n",
    "        func.sum(dq_agg_view.c.null_net_ord_id).label(\"null_net_ord_id\"),\n",
    "        func.sum(dq_agg_view.c.null_sell_cty).label(\"null_sell_cty\"),\n",
    "    ).where(or_(dq_agg_view.c.ord_date==max_date, dq_agg_view.c.ord_date==prev_dt))\n",
    "    .group_by(dq_agg_view.c.ord_date)\n",
    "    .order_by(desc(dq_agg_view.c.ord_date))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sum_canc = (\n",
    "    Select(\n",
    "        dq_agg_view.c.ord_date, \n",
    "        func.sum(dq_agg_view.c.total_canceled_orders).label(\"total_canceled_orders\"),\n",
    "        func.sum(dq_agg_view.c.null_cans_code).label(\"null_cans_code\"),\n",
    "        func.sum(dq_agg_view.c.null_cans_dt_time).label(\"null_cans_dt_time\")\n",
    "    ).where(or_(dq_agg_view.c.ord_date==max_date, dq_agg_view.c.ord_date==prev_dt))\n",
    "    .group_by(dq_agg_view.c.ord_date)\n",
    "    .order_by(desc(dq_agg_view.c.ord_date))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col_sum_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_stmt(col_sum_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_canc = run_stmt(col_sum_canc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_canc = pd.DataFrame(res_canc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_canc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_df[\"ord_date\"] = tmp_df[\"ord_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Percentage and Difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_total = int(tmp_df[\"total_orders\"][0])\n",
    "curr_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict = {\n",
    "    \"curr_date\": \"Current Date\",\n",
    "    \"ord_date\": \"Order Date\",\n",
    "    \"seller_np\": \"Seller NP\",\n",
    "    \"null_fulfilment_id\": \"Fulfilment ID\",\n",
    "    \"null_net_tran_id\": \"Net Transaction ID\",\n",
    "    \"null_qty\": \"Quantity\",\n",
    "    \"null_itm_fulfilment_id\": \"Item Fulfilment ID\",\n",
    "    \"null_del_pc\": \"Delivery Pincode\",\n",
    "    \"null_created_date_time\": \"Created Date\",\n",
    "    \"null_domain\": \"Domain\",\n",
    "    \"null_del_cty\": \"Delivery City\",\n",
    "    \"null_cans_code\": \"Cancellation Code\",\n",
    "    \"null_cans_dt_time\": \"Cancellation Date\",\n",
    "    \"null_ord_stats\": \"Order Status\",\n",
    "    \"null_fulfil_status\": \"Fulfilment Status\",\n",
    "    \"null_itm_cat\": \"Item Category\",\n",
    "    \"null_cat_cons\": \"Category\",\n",
    "    \"null_sell_pincode\": \"Seller Pincode\",\n",
    "    \"null_prov_id\": \"Provider ID\",\n",
    "    \"null_itm_id\": \"Item ID\",\n",
    "    \"null_sell_np\": \"Null Seller NP\",\n",
    "    \"null_net_ord_id\": \"Network Order ID\",\n",
    "    \"null_sell_cty\": \"Seller City\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "tmp_dict = {}\n",
    "\n",
    "for col in tmp_df.columns:\n",
    "    if col.__contains__(\"null\"):\n",
    "        per = np.round((int(tmp_df[col][0])/curr_total)*100,4)\n",
    "        if per > 0:\n",
    "            tmp_dict = {}\n",
    "            tmp_dict['title'] = cols_dict[col]\n",
    "            tmp_dict['series'] = [float(per)]\n",
    "            res.append(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Totals Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_trend = (\n",
    "    Select(\n",
    "        dq_agg_view.c.ord_date.label(\"ord_date\"),\n",
    "        func.sum(dq_agg_view.c.total_orders).label(\"total_orders\"),\n",
    "        func.sum(dq_agg_view.c.null_fulfilment_id).label(\"null_fulfilment_id\"),\n",
    "        func.sum(dq_agg_view.c.null_net_tran_id).label(\"null_net_tran_id\"),\n",
    "        func.sum(dq_agg_view.c.null_qty).label(\"null_qty\"),\n",
    "        func.sum(dq_agg_view.c.null_itm_fulfilment_id).label(\"null_itm_fulfilment_id\"),\n",
    "        func.sum(dq_agg_view.c.null_del_pc).label(\"null_del_pc\"),\n",
    "        func.sum(dq_agg_view.c.null_created_date_time).label(\"null_created_date_time\"),\n",
    "        func.sum(dq_agg_view.c.null_domain).label(\"null_domain\"),\n",
    "        func.sum(dq_agg_view.c.null_del_cty).label(\"null_del_cty\"),\n",
    "        func.sum(dq_agg_view.c.null_ord_stats).label(\"null_ord_stats\"),\n",
    "        func.sum(dq_agg_view.c.null_fulfil_status).label(\"null_fulfil_status\"),\n",
    "        func.sum(dq_agg_view.c.null_itm_cat).label(\"null_itm_cat\"),\n",
    "        func.sum(dq_agg_view.c.null_cat_cons).label(\"null_cat_cons\"),\n",
    "        func.sum(dq_agg_view.c.null_sell_pincode).label(\"null_sell_pincode\"),\n",
    "        func.sum(dq_agg_view.c.null_prov_id).label(\"null_prov_id\"),\n",
    "        func.sum(dq_agg_view.c.null_itm_id).label(\"null_itm_id\"),\n",
    "        func.sum(dq_agg_view.c.null_sell_np).label(\"null_sell_np\"),\n",
    "        func.sum(dq_agg_view.c.null_net_ord_id).label(\"null_net_ord_id\"),\n",
    "        func.sum(dq_agg_view.c.null_sell_cty).label(\"null_sell_cty\"),\n",
    "        func.sum(dq_agg_view.c.total_canceled_orders).label(\"total_canceled_orders\"),\n",
    "        func.sum(dq_agg_view.c.null_cans_code).label(\"null_cans_code\"),\n",
    "        func.sum(dq_agg_view.c.null_cans_dt_time).label(\"null_cans_dt_time\") \n",
    "    ).group_by(dq_agg_view.c.ord_date)\n",
    "    .order_by(desc(dq_agg_view.c.ord_date))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend = pd.DataFrame(run_stmt(ord_trend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = pd.DataFrame()\n",
    "df_small = pd.DataFrame()\n",
    "\n",
    "df_big[ev.cols_dict[\"ord_date\"]] = df_trend[[\"ord_date\"]]\n",
    "df_small[ev.cols_dict[\"ord_date\"]] = df_trend[[\"ord_date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_trend.columns:\n",
    "    if col not in [\"ord_date\", \"total_orders\"]:\n",
    "        try:\n",
    "            mean_trend = df_trend[col].mean() \n",
    "            if mean_trend > 0:\n",
    "                if mean_trend > 500:\n",
    "                    df_big.loc[:,[ev.cols_dict[col]]] = df_trend[col]\n",
    "                elif mean_trend < 500 and mean_trend > 1:\n",
    "                    df_small.loc[:,[ev.cols_dict[col]]] = df_trend[col]\n",
    "                # print(col, df_trend[col].mean())\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(df_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_big.columns:\n",
    "    try:\n",
    "        if col != \"Order Date\":\n",
    "            df_big.loc[:,[col]] = df_big[col].astype(int)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = df_big.head(5).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[val for val in test_dict[\"Delivery City\"].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in test_dict.keys():\n",
    "    if key not in (\"Order Date\",\"categories\"):\n",
    "        print(key)\n",
    "        res_dict = {}\n",
    "        res_dict[\"name\"] = key\n",
    "        res_dict[\"data\"] = [val for val in test_dict[key].values()]\n",
    "        output.append(res_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seller with Highest Missing Data \n",
    "\n",
    "cancel_highest_missing_pid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt_curr = Select(\n",
    "  dq_agg_sum.c.ord_date,\n",
    "  dq_agg_sum.c.seller_np,\n",
    "  func.sum(dq_agg_sum.c.total_orders).label(\"total_orders\"),\n",
    "  func.sum(dq_agg_sum.c.sum_missing_cols).label(\"missing_val\")).where(\n",
    "    dq_agg_sum.c.ord_date==max_date).group_by(\n",
    "      dq_agg_sum.c.ord_date).group_by(\n",
    "    dq_agg_sum.c.seller_np).order_by(desc(func.sum(dq_agg_sum.c.sum_missing_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stmt_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_stmt(stmt_curr, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"missing_percentage\"] = df[\"missing_val\"]/df[\"total_orders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"missing_percentage\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_frame = {\n",
    "  \"id\":\"\",\n",
    "  \"count\":\"\",\n",
    "  \"increased\":\"\",\n",
    "  \"variancePercentage\":\"\",\n",
    "  \"varianceText\":\"\"\n",
    "}\n",
    "json_str = []\n",
    "threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.index:\n",
    "  print(x)\n",
    "  json_frame = {\n",
    "  \"id\":\"\",\n",
    "  \"count\":\"\",\n",
    "  \"increased\":\"\",\n",
    "  \"variancePercentage\":\"\",\n",
    "  \"varianceText\":\"\"\n",
    "    }\n",
    "  json_frame[\"id\"] = df.iloc[x][\"seller_np\"]\n",
    "  json_frame[\"count\"] = np.round(float((df.iloc[x][\"missing_percentage\"])),2)\n",
    "  json_frame[\"increased\"] = True if df.iloc[x][\"missing_percentage\"] > 0 else \"False\"\n",
    "  json_frame[\"variancePercentage\"] = float(threshold*100)\n",
    "  json_frame[\"varianceText\"] = \"Threshold\"\n",
    "  print(json_frame)\n",
    "  json_str.append(json_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detail Completed Table Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Logic.base_queries as bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = Select(\n",
    "  dq_agg_sum.c.seller_np,\n",
    "  func.sum(dq_agg_sum.c.total_orders).label(\"total_orders\"),\n",
    "  func.sum(dq_agg_sum.c.sum_missing_cols).label(\"sum_missing_cols\")\n",
    ").where(dq_agg_sum.c.ord_date==max_date).group_by(\n",
    "    dq_agg_sum.c.seller_np).order_by(desc(func.sum(dq_agg_sum.c.sum_missing_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(run_stmt(stmt, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"missing_percentage\"] = df[\"sum_missing_cols\"]/df[\"total_orders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"missing_percentage\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = {\n",
    "    \"seller_np\": \"\",\n",
    "    \"null_itm_cat\":0 ,\n",
    "    \"total_orders\":0,\n",
    "    \"missing_percentage\":0\n",
    "}\n",
    "\n",
    "json_frame = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.index:\n",
    "    json_str = {\n",
    "        \"seller_np\": \"\",\n",
    "        \"null_itm_cat\":0,\n",
    "        \"total_orders\":0,\n",
    "        \"missing_percentage\":0\n",
    "        }\n",
    "    json_str[\"seller_np\"] = df.loc[x][\"seller_np\"]\n",
    "    json_str[\"null_itm_cat\"] = int(df.loc[x][\"sum_missing_cols\"])\n",
    "    json_str[\"total_orders\"] = int(df.loc[x][\"total_orders\"])\n",
    "    json_str[\"missing_percentage\"] = np.round(float(df.loc[x][\"missing_percentage\"]),2)\n",
    "    json_frame.append(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancelled Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = Select(\n",
    "  dq_agg_sum.c.seller_np,\n",
    "  func.sum(dq_agg_sum.c.total_canceled_orders).label(\"total_orders\"),\n",
    "  func.sum(dq_agg_sum.c.canc_metrices).label(\"sum_missing_cols\")\n",
    ").where(dq_agg_sum.c.ord_date==max_date).group_by(\n",
    "    dq_agg_sum.c.seller_np).order_by(desc(\n",
    "      func.sum(dq_agg_sum.c.total_canceled_orders)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(run_stmt(stmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sum_missing_cols\"].replace(0,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"missing_percentage\"] = df[\"sum_missing_cols\"] / df[\"total_orders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = Select(dq_col_sum.c.ord_date,\n",
    "       func.sum(dq_col_sum.c.null_del_cty).label(\"null_del_cty\"),\n",
    "       func.sum(dq_col_sum.c.null_itm_cat).label(\"null_itm_cat\"),\n",
    "       func.sum(dq_col_sum.c.null_cat_cons).label(\"null_cat_cons\"),\n",
    "       func.sum(dq_col_sum.c.null_cans_code).label(\"null_cans_code\"),\n",
    "       func.sum(dq_col_sum.c.null_cans_dt_time).label(\"null_cans_dt_time\")\n",
    "       ).group_by(dq_col_sum.c.ord_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(run_stmt(stmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"ord_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ser = {\n",
    "#   'name': 'col_name',\n",
    "#   'date': []\n",
    "# }\n",
    "\n",
    "# cat = ['date_range']\n",
    "\n",
    "final_json = {\n",
    "  'title':'Chart Title',\n",
    "  'series':[],\n",
    "  'categories': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col == 'ord_date':\n",
    "        # Ensure the 'ord_date' column is treated as a string\n",
    "        final_json['categories'] = df[col].astype(str).tolist()\n",
    "    else:\n",
    "        # Create a series dictionary\n",
    "        data_ser = {\n",
    "            'name': cols_dict[col],\n",
    "            'data': df[col].astype(int).tolist()  # Convert column to list\n",
    "        }\n",
    "        \n",
    "        # Add the series to the final JSON\n",
    "        final_json['series'].append(data_ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json['title'] = 'Columns with Highest Missing Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
