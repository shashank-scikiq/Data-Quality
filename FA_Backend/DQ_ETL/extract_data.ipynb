{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env loaded in utils.\n"
     ]
    }
   ],
   "source": [
    "from utils import DQ_TBL, DIM_ORD_STAT, DIM_SELLERS\n",
    "from utils import PG_USER, PG_PASSWD, PG_HOST, PG_PORT, PG_DB, PG_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EXT_ATH import process_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_mapping = {\n",
    "  \"base_od_dq_nhm.sql\": \"dq_main\",\n",
    "  \"base_dim_sellers.sql\" : \"dim_sellers\",\n",
    "  \"base_dim_order_status\" : \"dim_order_status\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = f\"postgresql+psycopg://{PG_USER}:{PG_PASSWD}@{PG_HOST}:{PG_PORT}/{PG_DB}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_results(results):\n",
    "    final_data = []\n",
    "    columns = [x[\"VarCharValue\"] for x in results[\"rows\"][0][\"Data\"]]\n",
    "    rows = [list(map(lambda field: field.get('VarCharValue', ''), row['Data'])) for row in results['rows'][1:]]\n",
    "    for data in rows:\n",
    "        final_data.append(data)\n",
    "    return pd.DataFrame(columns=columns, data=final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dates(start_date, period='days'):\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.now().date()\n",
    "    date_list = []\n",
    "\n",
    "    while start_date.date() <= end_date:\n",
    "        date_list.append(start_date.date().strftime(format=\"%Y-%m-%d\"))\n",
    "\n",
    "        if period == 'days':\n",
    "            start_date += timedelta(days=1)\n",
    "        elif period == 'months':\n",
    "            if start_date.month == 12:\n",
    "                start_date = start_date.replace(year=start_date.year + 1, month=1)\n",
    "            else:\n",
    "                next_month = start_date.month + 1\n",
    "                try:\n",
    "                    start_date = start_date.replace(month=next_month)\n",
    "                except ValueError:\n",
    "                    # Handle the cases like transitioning from Jan 31 to Feb\n",
    "                    start_date = start_date.replace(day=1, month=next_month) + timedelta(days=31)\n",
    "                    start_date = start_date.replace(day=1)\n",
    "    return date_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [DQ_TBL, DIM_ORD_STAT, DIM_SELLERS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_sql_stmt(conn_str:str, sql:str):\n",
    "  engine = create_engine(conn_str)\n",
    "  with engine.connect() as conn:\n",
    "    try:\n",
    "      conn.execute(text(sql))\n",
    "    except Exception as e:\n",
    "      raise e\n",
    "    else:\n",
    "      print(\"Execution Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in to_drop:\n",
    "  sql_stmt = f\"DROP TABLE {PG_SCHEMA}.{table} CASCADE\"\n",
    "  try:\n",
    "      exec_sql_stmt(conn_str, sql_stmt)\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP TABLE data_sanity.od_dq_nhm CASCADE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2024-05-01'\n",
    "dates_between = list_dates(start_date, period=\"months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_mapping = {\n",
    "    \"dq_main\":\"base_od_dq_nhm.sql\",\n",
    "    \"dim_sellers\":\"base_dim_sellers.sql\",\n",
    "    \"dim_order_status\":\"base_dim_order_status\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date_val in dates_between:\n",
    "    print(f\"Processing {date_val}\")\n",
    "    results = await process_date(tbl_name=\"nhm_order_fulfillment_subset_v1\",date=date_val,raw_query=dq_sql)\n",
    "    df = get_raw_results(results)\n",
    "    df.to_parquet(f\"D:\\\\DATA_DUMP\\\\DATA_QUALITY\\\\{tbl_name}_{date_val}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_name = \"od_dq_nhm\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
